{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Logreg with supervised TF-IDF, FNN, CNN, BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a4f43aab4394627b072f60035338d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b1702f2e8fd4dde9b9e1b5a8ef81fb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd825f89203842a985b492429f424f78",
              "IPY_MODEL_26bf10f26de34ad6be8d93e08aea93e6"
            ]
          }
        },
        "3b1702f2e8fd4dde9b9e1b5a8ef81fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd825f89203842a985b492429f424f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0db38a1745054acf8e6c8fe0d025d3cc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10b3e51b94ea4cff9f7a9b9586d2df07"
          }
        },
        "26bf10f26de34ad6be8d93e08aea93e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_362c4459a9c544fea3c91851c3f8a518",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 704kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c97648277dd14f63b4fbc96176c487b7"
          }
        },
        "0db38a1745054acf8e6c8fe0d025d3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10b3e51b94ea4cff9f7a9b9586d2df07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "362c4459a9c544fea3c91851c3f8a518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c97648277dd14f63b4fbc96176c487b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70165d6548e64c97941583781af02390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9402f2cf9f69473d9b3abb811bb6a9d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_725e32bfd7a74c4da7dfb8f61fdd163e",
              "IPY_MODEL_ee511de2871a4840be31c62d0de8e6ef"
            ]
          }
        },
        "9402f2cf9f69473d9b3abb811bb6a9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "725e32bfd7a74c4da7dfb8f61fdd163e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e84edbebf9ac4698a9ef018e57242335",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_950223bdc4634e2ca2fcabf0531013e2"
          }
        },
        "ee511de2871a4840be31c62d0de8e6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d66d1ec137c84e43a2425b55bbda085b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:06&lt;00:00, 69.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f89a9d350354f22ad9aeca25f264949"
          }
        },
        "e84edbebf9ac4698a9ef018e57242335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "950223bdc4634e2ca2fcabf0531013e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d66d1ec137c84e43a2425b55bbda085b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f89a9d350354f22ad9aeca25f264949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7895f957a6094fa883868719653427c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a70f823b2fff43b3bd9c2c6db18212b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3ee592ed6db4153a40ef3116e45cf92",
              "IPY_MODEL_bb1bf541497b469bb991c17980726a2c"
            ]
          }
        },
        "a70f823b2fff43b3bd9c2c6db18212b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3ee592ed6db4153a40ef3116e45cf92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd2281963efb4a089520ad43d198079b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2056ec81e8904c25bee719652e351bcd"
          }
        },
        "bb1bf541497b469bb991c17980726a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84a982f58195479fa47743e2aec2fa13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 71.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ad0d29554a14c86a52a6c35863f1c16"
          }
        },
        "dd2281963efb4a089520ad43d198079b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2056ec81e8904c25bee719652e351bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84a982f58195479fa47743e2aec2fa13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ad0d29554a14c86a52a6c35863f1c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyORhfG4OFQS",
        "colab_type": "text"
      },
      "source": [
        "# Logreg, FCNN, CNN, BERT baselines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "pBMSJz6vV1QC",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "586e2f8d-88e9-4db8-cee1-ab9d5652c2fb"
      },
      "source": [
        "!pip install spacy textvec\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Collecting textvec\n",
            "  Downloading https://files.pythonhosted.org/packages/72/4c/07658a77f8384c65d60d3d9d872ef602428d245663a4fad09d19f2cb36e7/textvec-2.0-py3-none-any.whl\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.1.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from textvec) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from textvec) (0.22.2.post1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from textvec) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->textvec) (0.16.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->textvec) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->textvec) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->textvec) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->textvec) (1.14.24)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->textvec) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.24 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->textvec) (1.17.24)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->textvec) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->smart-open>=1.2.1->gensim->textvec) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->smart-open>=1.2.1->gensim->textvec) (0.15.2)\n",
            "Installing collected packages: textvec\n",
            "Successfully installed textvec-2.0\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N7cPdTVMMY8",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3533b6fb-be36-4405-ff36-bfe581eed8d7"
      },
      "source": [
        "# Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preprocessing\n",
        "import nltk\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# ML\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from textvec.vectorizers import TforVectorizer\n",
        "\n",
        "# NNs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Utils\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfN8FyP2bez3",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "3825dd36-7282-4b67-d3ad-cb2e46ce5b0f"
      },
      "source": [
        "# BERT Model\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 27.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.3MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=c0d4ccbb138d02ecf4b1bcb8ae4748a9ec0e0d58ee32cce96e6ff5d3dd103a70\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2YBaxUFV1QJ",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5cd94692-d7aa-43dc-9879-959e1a9d0a06"
      },
      "source": [
        "# Define datafolder\n",
        "# If you are using google colab you can put data in /content/drive/My Drive/Colab/Real-or-Not/data/\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    is_in_colab = True\n",
        "    \n",
        "except:\n",
        "    is_in_colab = False\n",
        "\n",
        "if is_in_colab:\n",
        "    drive.mount('/content/drive')\n",
        "    data_folder = r'/content/drive/My Drive/Colab/Real-or-Not/data/'\n",
        "else:\n",
        "    # Kaggle kernel\n",
        "    data_folder = r'../input/nlp-getting-started'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr5xZ5L7NcnT",
        "colab_type": "text"
      },
      "source": [
        "# Look at data and task review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21C-CKh7OC4T",
        "colab_type": "text"
      },
      "source": [
        " We are predicting whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0. Its binary classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5q8MdnlNh4v",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "96bb7e37-5560-456e-8a99-21cb2fac317f"
      },
      "source": [
        "data = pd.read_csv(data_folder + '/train.csv')\n",
        "data.head(30)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>There's an emergency evacuation happening now ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Three people died from the heat wave so far</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What's up man?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I love fruits</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Summer is lovely</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My car is so fast</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>this is ridiculous....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>London is cool ;)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love skiing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What a wonderful day!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>36</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LOOOOOOL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No way...I can't eat that shit</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Was in NYC last week!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love my girlfriend</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cooool :)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Do you like pasta?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id keyword  ...                                               text target\n",
              "0    1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1    4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2    5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3    6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4    7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "5    8     NaN  ...  #RockyFire Update => California Hwy. 20 closed...      1\n",
              "6   10     NaN  ...  #flood #disaster Heavy rain causes flash flood...      1\n",
              "7   13     NaN  ...  I'm on top of the hill and I can see a fire in...      1\n",
              "8   14     NaN  ...  There's an emergency evacuation happening now ...      1\n",
              "9   15     NaN  ...  I'm afraid that the tornado is coming to our a...      1\n",
              "10  16     NaN  ...        Three people died from the heat wave so far      1\n",
              "11  17     NaN  ...  Haha South Tampa is getting flooded hah- WAIT ...      1\n",
              "12  18     NaN  ...  #raining #flooding #Florida #TampaBay #Tampa 1...      1\n",
              "13  19     NaN  ...            #Flood in Bago Myanmar #We arrived Bago      1\n",
              "14  20     NaN  ...  Damage to school bus on 80 in multi car crash ...      1\n",
              "15  23     NaN  ...                                     What's up man?      0\n",
              "16  24     NaN  ...                                      I love fruits      0\n",
              "17  25     NaN  ...                                   Summer is lovely      0\n",
              "18  26     NaN  ...                                  My car is so fast      0\n",
              "19  28     NaN  ...                       What a goooooooaaaaaal!!!!!!      0\n",
              "20  31     NaN  ...                             this is ridiculous....      0\n",
              "21  32     NaN  ...                                  London is cool ;)      0\n",
              "22  33     NaN  ...                                        Love skiing      0\n",
              "23  34     NaN  ...                              What a wonderful day!      0\n",
              "24  36     NaN  ...                                           LOOOOOOL      0\n",
              "25  37     NaN  ...                     No way...I can't eat that shit      0\n",
              "26  38     NaN  ...                              Was in NYC last week!      0\n",
              "27  39     NaN  ...                                 Love my girlfriend      0\n",
              "28  40     NaN  ...                                          Cooool :)      0\n",
              "29  41     NaN  ...                                 Do you like pasta?      0\n",
              "\n",
              "[30 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoxsIQ1WV1QN",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "d425c89f-7156-4edc-ed48-b0334fc90cea"
      },
      "source": [
        "# Look at the class ratio\n",
        "data.target.hist()\n",
        "data.target.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    7613.00000\n",
              "mean        0.42966\n",
              "std         0.49506\n",
              "min         0.00000\n",
              "25%         0.00000\n",
              "50%         0.00000\n",
              "75%         1.00000\n",
              "max         1.00000\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C60y0sFURiT",
        "colab_type": "text"
      },
      "source": [
        "We have a good balanced dataset. But keep in mind that there are situations when the dataset can be unbalanced so we have to do oversampling or downsampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XNa-eVSIV1QW",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "CprzzdlxV1Qa",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text):\n",
        "  text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',    # Substitute different urls with \"url\" token.\n",
        "                  'url', text)\n",
        "  text = re.sub('#', '', text)              # Delete hashtag signs.\n",
        "  text = re.sub('\\d+[.,]?\\d*', 'num', text)  # Substitute different numbers with \"num\" token.                                                 \n",
        "  text = re.sub('@\\w+_?\\w*', 'username', text)  # Substitute different usernames with 'username' token.                                                       \n",
        "  return text\n",
        "\n",
        "def lemmatize(text):\n",
        "  preprocessed_tokens = []    # preprocessed_tokens will be lemmatized, stopwords removed and lowercased\n",
        "  nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])   # We will not use NER and syntactic parser.\n",
        "  doc = nlp(text)\n",
        "  for token in doc:\n",
        "    if not token.is_stop:\n",
        "      preprocessed_tokens.append(token.lemma_.lower())\n",
        "  return ' '.join(preprocessed_tokens)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPze5wE-ZYMt",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['text'] = data.text.apply(clean)    # Clean texts.\n",
        "data['lemmatized_text'] = data.text.apply(lemmatize)  # Add new column with lemmatized and preprocessed texts. This task requires a lot of time.\n",
        "data.drop(['keyword', 'location'], axis=1, inplace=True) # We don't need 'keyword', 'location' columns."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeCIkIA96gK8",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "0ddbbaa8-c4cb-4021-c2af-9310141b0e3d"
      },
      "source": [
        "# data.to_pickle(data_folder+'/cleaned_lemmatized_train.pkl')\n",
        "data = pd.read_pickle(data_folder + 'cleaned_lemmatized_train.pkl')\n",
        "data.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>lemmatized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
              "      <td>1</td>\n",
              "      <td>deed reason earthquake allah forgive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask . canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>resident ask ' shelter place ' notify officer ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>num people receive wildfires evacuation orders...</td>\n",
              "      <td>1</td>\n",
              "      <td>num people receive wildfire evacuation order c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
              "      <td>1</td>\n",
              "      <td>get send photo ruby alaska smoke wildfire pour...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>RockyFire Update =&gt; California Hwy. num closed...</td>\n",
              "      <td>1</td>\n",
              "      <td>rockyfire update = &gt; california hwy . num clos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>flood disaster Heavy rain causes flash floodin...</td>\n",
              "      <td>1</td>\n",
              "      <td>flood disaster heavy rain cause flash flooding...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13</td>\n",
              "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
              "      <td>1</td>\n",
              "      <td>hill fire wood ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>14</td>\n",
              "      <td>There's an emergency evacuation happening now ...</td>\n",
              "      <td>1</td>\n",
              "      <td>emergency evacuation happen building street</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
              "      <td>1</td>\n",
              "      <td>afraid tornado come area ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                    lemmatized_text\n",
              "0   1  ...               deed reason earthquake allah forgive\n",
              "1   4  ...            forest fire near la ronge sask . canada\n",
              "2   5  ...  resident ask ' shelter place ' notify officer ...\n",
              "3   6  ...  num people receive wildfire evacuation order c...\n",
              "4   7  ...  get send photo ruby alaska smoke wildfire pour...\n",
              "5   8  ...  rockyfire update = > california hwy . num clos...\n",
              "6  10  ...  flood disaster heavy rain cause flash flooding...\n",
              "7  13  ...                                 hill fire wood ...\n",
              "8  14  ...        emergency evacuation happen building street\n",
              "9  15  ...                       afraid tornado come area ...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGiVXA-krkrM",
        "colab_type": "text"
      },
      "source": [
        "## BOW features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaSP7SwJV1Qx",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data on train and test.\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, data.target, train_size = 0.8, random_state=42)   "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "V9mYqV6KV1RD",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will use TF-IDF and TFOR as features describing texts.\n",
        "# We will try word level features using lemmas and char level features. \n",
        "\n",
        "word_vectorizer = TfidfVectorizer(    # TF-IDF for word level features.\n",
        "    analyzer='word',                  # Word level tokenization.\n",
        "    ngram_range=(1, 1),               # We don't use ngrams. But you can try.\n",
        "    max_features=10000,      # Number of max features (it will be shape of our training matrix: shape=(num_documents,max_features))\n",
        "    max_df=0.7,                        # We will not use tokens that are found in more than 70 percent of documents\n",
        "    min_df=1)                          # We will not use tokens that are found only in 1 document\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(    # TF-IDF for char level features.\n",
        "    analyzer='char',                  # Char level tokenization.                            \n",
        "    ngram_range=(1, 4),               # We use [1..4]grams. \n",
        "    max_features=30000,                                   \n",
        "    max_df=0.7,                                            \n",
        "    min_df=1\n",
        "    )\n",
        "\n",
        "# Get char ngrams features for the train set and the validation set.\n",
        "word_vectorizer.fit(data.lemmatized_text)\n",
        "\n",
        "train_w_features = word_vectorizer.fit_transform(X_train.lemmatized_text)\n",
        "val_w_features = word_vectorizer.transform(X_val.lemmatized_text)\n",
        "\n",
        "# Get lemma features for the train set and the validation set.\n",
        "char_vectorizer.fit(data.text)\n",
        "\n",
        "train_c_features = char_vectorizer.transform(X_train.text)\n",
        "val_c_features = char_vectorizer.transform(X_val.text)\n",
        "\n",
        "# We can use information about classes in features with help of supervised vectorizer. \n",
        "# For example, TFOR (for binary classification) from textvec lib. Let's fit TFOR on char ngrams.\n",
        "tfor = TforVectorizer()\n",
        "\n",
        "tfor_train = tfor.fit_transform(char_vectorizer.transform(X_train.text), y_train)\n",
        "tfor_val = tfor.transform(char_vectorizer.transform(X_val.text))\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zcafxVPuV1RF",
        "colab_type": "text"
      },
      "source": [
        "# Classic models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fVigEZaYV1RG",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8INxpWjgp94",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c777ef50-2d21-4003-92d4-89578aa15250"
      },
      "source": [
        "# Logreg on tf-idf char ngrams from cleaned texts\n",
        "\n",
        "# You should try different values of C [0.01, 0.1, 1, 10], solver ['liblinear', 'sag'], penalty ['l1', 'l2']\n",
        "\n",
        "logreg = LogisticRegression(C=1, solver='sag')             \n",
        "logreg.fit(train_c_features, y_train)\n",
        "preds = logreg.predict(val_c_features)\n",
        "print(classification_report(y_val, preds))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84       874\n",
            "           1       0.83      0.68      0.75       649\n",
            "\n",
            "    accuracy                           0.81      1523\n",
            "   macro avg       0.81      0.79      0.80      1523\n",
            "weighted avg       0.81      0.81      0.80      1523\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf0IdFszhGym",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "dc8fa01c-dee5-454e-a0dc-ebc5e5691708"
      },
      "source": [
        "# Logreg on tf-idf lowercased lemmas from cleaned, lemmatized, stop words filtered texts.\n",
        "\n",
        "# You should try different values of C [0.01, 0.1, 1, 10], solver ['liblinear', 'sag'], penalty ['l1', 'l2']\n",
        "\n",
        "logreg = LogisticRegression(C=1, solver='sag')               \n",
        "logreg.fit(train_w_features, y_train)\n",
        "preds = logreg.predict(val_w_features)\n",
        "print(classification_report(y_val, preds))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       874\n",
            "           1       0.80      0.67      0.73       649\n",
            "\n",
            "    accuracy                           0.79      1523\n",
            "   macro avg       0.79      0.77      0.78      1523\n",
            "weighted avg       0.79      0.79      0.79      1523\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiXsrOObqb3G",
        "colab_type": "text"
      },
      "source": [
        "**!!! It is possible if lemmatization doesn't work because stop words or special forms of words can be important features.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "covi2J2up5KR",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9a9a3987-bd9a-4c4a-f715-bfa841dfbc62"
      },
      "source": [
        "# Logreg on tfor char ngrams from cleaned texts\n",
        "\n",
        "# You should try different values of C [0.01, 0.1, 1, 10], solver ['liblinear', 'sag'], penalty ['l1', 'l2']\n",
        "\n",
        "logreg = LogisticRegression(C=1, solver='sag')            \n",
        "logreg.fit(tfor_train, y_train)\n",
        "preds = logreg.predict(tfor_val)\n",
        "print(classification_report(y_val, preds))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.84       874\n",
            "           1       0.81      0.71      0.76       649\n",
            "\n",
            "    accuracy                           0.81      1523\n",
            "   macro avg       0.81      0.79      0.80      1523\n",
            "weighted avg       0.81      0.81      0.80      1523\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Tc41-vlP6R",
        "colab_type": "text"
      },
      "source": [
        "TFOR is a little better. But TFOR must give better balance between precision and recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7p5aufh8V1Re",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEESYlWWZL47",
        "colab_type": "text"
      },
      "source": [
        "## Define functions for learning NNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PrmMt9irV1Rf",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resolve what Tensors we will use - GPU or CPU. \n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device('cuda:0')\n",
        "    from torch.cuda import FloatTensor, LongTensor            # Import GPU Tensors.\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    from torch import FloatTensor, LongTensor                 # Import CPU Tensors."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gIuBuJajOFQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18364dff-733c-4165-eda8-a1c1b7130b2a"
      },
      "source": [
        "is_cuda"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "8b8PeuBQV1Rv",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function for training NN models.\n",
        "\n",
        "def fit(model, loss_function, train_data=None, val_data=None, optimizer=None,\n",
        "        epoch_count=1, batch_size=1, scheduler=None, alpha=1, type_nn=None):\n",
        "  \n",
        "    train_history = []\n",
        "    val_history = []\n",
        "\n",
        "    for epoch in range(epoch_count):\n",
        "            name_prefix = '[{} / {}] '.format(epoch + 1, epoch_count)\n",
        "            epoch_train_score = 0\n",
        "            epoch_val_score = 0\n",
        "            \n",
        "            if train_data:\n",
        "                epoch_train_score = do_epoch(model, loss_function, train_data, batch_size, \n",
        "                                              optimizer, name_prefix + 'Train:', alpha=alpha, type_nn=type_nn,\n",
        "                                             scheduler=scheduler)\n",
        "                train_history.append(epoch_train_score)\n",
        "\n",
        "            if val_data:\n",
        "                name = '  Val:'\n",
        "                if not train_data:\n",
        "                    name = ' Test:'\n",
        "                epoch_val_score = do_epoch(model, loss_function, val_data, batch_size, \n",
        "                                             optimizer=None, name=name_prefix + name, alpha=alpha, type_nn=type_nn,\n",
        "                                           scheduler=scheduler)\n",
        "                \n",
        "                val_history.append(epoch_val_score)\n",
        "\n",
        "    return train_history, val_history\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "hmaj7gvAV1Rx",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a function for generating one epoch for each NN model (BERT, FNN, CNN).\n",
        "\n",
        "def do_epoch(model, loss_function, data, batch_size, optimizer=None, name=None, alpha=1, type_nn=None, scheduler=None):\n",
        "    \"\"\"\n",
        "       One epoch generation\n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "    epoch_loss = 0\n",
        "   \n",
        "    batch_count = len(data)\n",
        "   \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batch_count) as progress_bar:               \n",
        "            for ind, batch in enumerate(data):\n",
        "                if type_nn == 'BERT':\n",
        "                  X_batch, X_mask, y_batch =  batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "                  loss, prediction = model(X_batch, token_type_ids=None, attention_mask=X_mask, labels=y_batch)\n",
        "                if type_nn == 'CNN':\n",
        "                  X_batch, y_batch = batch\n",
        "                  prediction = model(X_batch)\n",
        "                  loss = loss_function(prediction, y_batch)\n",
        "                if type_nn == 'FNN':\n",
        "                  X_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
        "                  prediction = model(X_batch)\n",
        "                  loss = loss_function(prediction, y_batch)\n",
        "\n",
        "                  for param in model.children():\n",
        "                    if type(param) == nn.Linear:\n",
        "                        loss += alpha * torch.abs(param.weight).sum()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                true_indices = torch.argmax(prediction, dim=1)\n",
        "                correct_samples = torch.sum(true_indices == y_batch).cpu().numpy()\n",
        "                accuracy += correct_samples / y_batch.shape[0]\n",
        "\n",
        "                if is_train:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    if scheduler: scheduler.step(accuracy)\n",
        "              \n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('Epoch {} - accuracy: {:.2f}, loss {:.2f}'.format(\n",
        "                    name, (accuracy / (ind+1)), epoch_loss / (ind+1))\n",
        "                )\n",
        "            \n",
        "            accuracy /= (ind + 1)\n",
        "            epoch_loss /= (ind + 1) \n",
        "            progress_bar.set_description(f'Epoch {name} - accuracy: {accuracy:.2f}, loss: {epoch_loss:.2f}')\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWXCaG_FavJw",
        "colab_type": "text"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arS06iCpa0eX",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0a4f43aab4394627b072f60035338d4a",
            "3b1702f2e8fd4dde9b9e1b5a8ef81fb5",
            "bd825f89203842a985b492429f424f78",
            "26bf10f26de34ad6be8d93e08aea93e6",
            "0db38a1745054acf8e6c8fe0d025d3cc",
            "10b3e51b94ea4cff9f7a9b9586d2df07",
            "362c4459a9c544fea3c91851c3f8a518",
            "c97648277dd14f63b4fbc96176c487b7"
          ]
        },
        "outputId": "ae99cca0-cf55-4e8d-b1d4-13e2032281df"
      },
      "source": [
        "# Preparing data\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a4f43aab4394627b072f60035338d4a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4qhTfS0Nx0y",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_for_bert(texts):\n",
        "  MAX_LEN = 0\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for tweet in texts:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_tweet = bert_tokenizer.encode(\n",
        "                        tweet,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        " \n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_tweet)\n",
        " \n",
        "    if len(encoded_tweet) > MAX_LEN:\n",
        "      MAX_LEN = len(encoded_tweet)\n",
        " \n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                        value=0, truncating=\"post\", padding=\"post\")\n",
        "  \n",
        "  # Make attention masks token -> 1, [PAD] -> 0\n",
        "  for tweet in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in tweet]\n",
        "    attention_masks.append(att_mask)\n",
        "    \n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21twlXWlT6F7",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data for BERT\n",
        "input_ids, attention_masks = prepare_data_for_bert(data.text)\n",
        "labels = data.target.values\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.25)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.25)\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmJOeMW_dbao",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(torch.tensor(train_inputs), torch.tensor(train_masks), torch.tensor(train_labels))\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(torch.tensor(validation_inputs), torch.tensor(validation_masks), torch.tensor(validation_labels))\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ua76ZZAdvFK",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "70165d6548e64c97941583781af02390",
            "9402f2cf9f69473d9b3abb811bb6a9d0",
            "725e32bfd7a74c4da7dfb8f61fdd163e",
            "ee511de2871a4840be31c62d0de8e6ef",
            "e84edbebf9ac4698a9ef018e57242335",
            "950223bdc4634e2ca2fcabf0531013e2",
            "d66d1ec137c84e43a2425b55bbda085b",
            "1f89a9d350354f22ad9aeca25f264949",
            "7895f957a6094fa883868719653427c2",
            "a70f823b2fff43b3bd9c2c6db18212b6",
            "c3ee592ed6db4153a40ef3116e45cf92",
            "bb1bf541497b469bb991c17980726a2c",
            "dd2281963efb4a089520ad43d198079b",
            "2056ec81e8904c25bee719652e351bcd",
            "84a982f58195479fa47743e2aec2fa13",
            "9ad0d29554a14c86a52a6c35863f1c16"
          ]
        },
        "outputId": "0994a4bd-c529-4a77-ca4e-5cc9dd54f368"
      },
      "source": [
        "# Load model\n",
        "bert = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "bert.cuda()   #To GPU"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70165d6548e64c97941583781af02390",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7895f957a6094fa883868719653427c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nng3mn4hhEyB",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "# Number of training epochs (between 2 and 4 recommended)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# AdamW is a class from the huggingface library. Read docs for get an idea of parameters.\n",
        "optimizer = AdamW(bert.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, you can try [1e-5 .. 5e-5]\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-2-mBvvnpFX",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "17c3436c-a2ad-4f68-ccff-71a3f9bbf2bd"
      },
      "source": [
        "train_history_bert, val_history_bert = fit(bert, loss_function=None, train_data=train_dataloader, val_data=validation_dataloader, optimizer=optimizer, epoch_count=epochs, batch_size=batch_size, type_nn='BERT', scheduler=scheduler, alpha=1, )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/357 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "Epoch [1 / 3] Train: - accuracy: 0.80, loss: 0.46: 100%|██████████| 357/357 [01:24<00:00,  4.23it/s]\n",
            "Epoch [1 / 3]   Val: - accuracy: 0.83, loss: 0.41: 100%|██████████| 119/119 [00:09<00:00, 12.31it/s]\n",
            "Epoch [2 / 3] Train: - accuracy: 0.87, loss: 0.32: 100%|██████████| 357/357 [01:29<00:00,  4.00it/s]\n",
            "Epoch [2 / 3]   Val: - accuracy: 0.83, loss: 0.44: 100%|██████████| 119/119 [00:09<00:00, 12.32it/s]\n",
            "Epoch [3 / 3] Train: - accuracy: 0.93, loss: 0.20: 100%|██████████| 357/357 [01:29<00:00,  4.00it/s]\n",
            "Epoch [3 / 3]   Val: - accuracy: 0.82, loss: 0.50: 100%|██████████| 119/119 [00:09<00:00, 12.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CXB0QbfsV1Rz",
        "colab_type": "text"
      },
      "source": [
        "## LinearNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUDfkgHRa4pl",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data for NN\n",
        "\n",
        "# Create the DataLoader for our training set. We will use TF-IDF matrix\n",
        "train_data = TensorDataset(torch.FloatTensor(train_c_features.toarray()), torch.tensor(np.array(y_train)))\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.  We will use TF-IDF matrix\n",
        "validation_data = TensorDataset(torch.FloatTensor(val_c_features.toarray()), torch.tensor(np.array(y_val)))\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "OaauF8d3V1R3",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit settings\n",
        "batch_size = 100\n",
        "epoch_count = 4\n",
        "\n",
        "# optim settings. You should try different values.\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 0.1\n",
        "alpha = 0.005\n",
        "\n",
        "# model settings. \n",
        "linear1_out = int(val_c_features.shape[1]**0.5)            # You should try different values.\n",
        "output = 2                                                 # Equals to num classes.\n",
        "dropout = 0.3                                              # You should try different values.\n",
        "\n",
        "\n",
        "model = nn.Sequential(nn.Linear(train_c_features.shape[1], linear1_out),\n",
        "                      nn.BatchNorm1d(linear1_out),\n",
        "#                       nn.Dropout(p=dropout, inplace=True),\n",
        "                      nn.ReLU(inplace=True),\n",
        "                      nn.Linear(linear1_out, output),\n",
        "                      nn.ReLU(inplace=True)\n",
        "                     ).to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "                        model.parameters(),\n",
        "                        lr=learning_rate, \n",
        "                        weight_decay=weight_decay\n",
        "                    )\n",
        "\n",
        "#"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WHOHn2xlGcv",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e20ada96-9331-4d78-a5b7-52754887d9a3"
      },
      "source": [
        "train_history, val_history = fit(model, loss_function, train_dataloader, validation_dataloader, optimizer, epoch_count, batch_size, scheduler=None, alpha=alpha, type_nn='FNN')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1 / 4] Train: - accuracy: 0.71, loss: 27.24: 100%|██████████| 61/61 [00:00<00:00, 83.32it/s]\n",
            "Epoch [1 / 4]   Val: - accuracy: 0.67, loss: 3.04: 100%|██████████| 16/16 [00:00<00:00, 121.65it/s]\n",
            "Epoch [2 / 4] Train: - accuracy: 0.76, loss: 1.59: 100%|██████████| 61/61 [00:00<00:00, 92.34it/s]\n",
            "Epoch [2 / 4]   Val: - accuracy: 0.77, loss: 1.24: 100%|██████████| 16/16 [00:00<00:00, 121.52it/s]\n",
            "Epoch [3 / 4] Train: - accuracy: 0.76, loss: 1.20: 100%|██████████| 61/61 [00:00<00:00, 96.27it/s]\n",
            "Epoch [3 / 4]   Val: - accuracy: 0.76, loss: 1.19: 100%|██████████| 16/16 [00:00<00:00, 126.67it/s]\n",
            "Epoch [4 / 4] Train: - accuracy: 0.77, loss: 1.18: 100%|██████████| 61/61 [00:00<00:00, 94.22it/s]\n",
            "Epoch [4 / 4]   Val: - accuracy: 0.78, loss: 1.16: 100%|██████████| 16/16 [00:00<00:00, 107.68it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2C3_pui8k0h",
        "colab_type": "text"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_GZQepJNOFRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data for torch dataset in Google colab or local\n",
        "train, val = train_test_split(data[['text', 'target']], train_size = 0.8, random_state=42)\n",
        "train.to_csv(data_folder + 'train_cnn.csv')\n",
        "val.to_csv(data_folder + 'val_cnn.csv')\n",
        "\n",
        "#In Kaggle Kernel I uploaded splitted train data\n",
        "#cnn_data = '../input/realornottrainsplitted/'"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCjHko_OEDyJ",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "257c068b-61a7-4952-db3c-a9c0eeb2ebc9"
      },
      "source": [
        "# Prepare torch dataset\n",
        "\n",
        "import torchtext\n",
        "\n",
        "MAX_TEXT_LEN = max(data.text.apply(lambda x: len(x)))\n",
        "\n",
        "train, val = train_test_split(data[['text', 'target']], train_size = 0.8, random_state=42)\n",
        "\n",
        "text_field = torchtext.data.Field(lower=True, include_lengths=False, fix_length=1000, batch_first=True)\n",
        "target_field = torchtext.data.Field(sequential=False, is_target=True, use_vocab=False)\n",
        "\n",
        "train_dataset = torchtext.data.TabularDataset(data_folder + 'train_cnn.csv', format='csv', fields={'text': ('text', text_field), 'target': ('target', target_field)})\n",
        "val_dataset = torchtext.data.TabularDataset(data_folder + 'val_cnn.csv', format='csv', fields={'text': ('text', text_field), 'target': ('target', target_field)})\n",
        "\n",
        "text_field.build_vocab(train_dataset, min_freq=2)\n",
        "target_field.build_vocab(train_dataset)\n",
        "vocab = text_field.vocab\n",
        "\n",
        "\n",
        "print('Vocab size: ', len(vocab))\n",
        "print(train_dataset[0].text)\n",
        "print(train_dataset[0].target)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size:  5927\n",
            "['courageous', 'and', 'honest', 'analysis', 'of', 'need', 'to', 'use', 'atomic', 'bomb', 'in', 'num', 'hiroshimanum', 'japanese', 'military', 'refused', 'surrender.', 'url']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PApWawpYFlp2",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define architecture of our CNN.\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, n_classes,\n",
        "                 kernel_sizes_cnn, filters_cnn: int, dense_size: int,\n",
        "                 dropout_rate: float = 0.,):\n",
        "        super().__init__()\n",
        "\n",
        "        self._n_classes = n_classes\n",
        "        self._vocab_size = vocab_size\n",
        "        self._embedding_size = embedding_size\n",
        "        self._kernel_sizes_cnn = kernel_sizes_cnn\n",
        "        self._filters_cnn = filters_cnn\n",
        "        self._dense_size = dense_size\n",
        "        self._dropout_rate = dropout_rate\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "\n",
        "        self.cnns = []\n",
        "        for i in range(len(kernel_sizes_cnn)):\n",
        "            in_channels = embedding_size\n",
        "\n",
        "            cnn = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, filters_cnn, kernel_sizes_cnn[i]),\n",
        "                nn.BatchNorm1d(filters_cnn),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "            cnn.apply(self.init_weights)\n",
        "\n",
        "            self.add_module(f'cnn_{i}', cnn)\n",
        "            self.cnns.append(cnn)\n",
        "        \n",
        "        # concatenated to hidden to classes\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(filters_cnn * len(kernel_sizes_cnn), dense_size),\n",
        "            nn.BatchNorm1d(dense_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(dense_size, n_classes)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def init_weights(module):\n",
        "        if type(module) == nn.Linear or type(module) == nn.Conv1d:\n",
        "            nn.init.kaiming_normal_(module.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.embedding(x)\n",
        "        x0 = torch.transpose(x0, 1, 2)\n",
        "\n",
        "        outputs0 = []\n",
        "        outputs1 = []\n",
        "\n",
        "        for i in range(len(self.cnns)):\n",
        "            cnn = getattr(self, f'cnn_{i}')\n",
        "            # apply cnn and global max pooling\n",
        "            pooled, _ = cnn(x0).max(dim=2)\n",
        "            outputs0.append(pooled)\n",
        "\n",
        "        x0 = torch.cat(outputs0, dim=1) if len(outputs0) > 1 else outputs0[0]\n",
        "        return self.projection(x0)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoEzXo55LJ9D",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4bc4e89e-d16d-4b08-d4dd-804503d540b8"
      },
      "source": [
        "# Prepare data loaders.\n",
        "train_loader, val_loader = torchtext.data.Iterator.splits((train_dataset, val_dataset),\n",
        "                                                           batch_sizes=(64, 64),\n",
        "                                                           sort=False,\n",
        "                                                           device='cuda')\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "print(batch)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 64]\n",
            "\t[.text]:[torch.cuda.LongTensor of size 64x1000 (GPU 0)]\n",
            "\t[.target]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNrXruLJSlRF",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Init CNN model and parameters.\n",
        "\n",
        "epochs = 8                        # you can different number of epochs. \n",
        "batch_size = 32                   # you can different number of batch size. \n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_size = 300\n",
        "n_classes = 2\n",
        "kernel_sizes = (1, 2, 3, 5)       # You can try different values.\n",
        "dense_size = 256                  # You can try different values.\n",
        "dropout = 0.5                     # You can try different values.\n",
        "filters_size = 512                # You can try different values.\n",
        "\n",
        "model = CNN(vocab_size, embedding_size, n_classes, kernel_sizes,\n",
        "            filters_size, dense_size, dropout)\n",
        "\n",
        "model.cuda()  # move model to GPU\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# AdamW is a class from the huggingface library\n",
        "\n",
        "# You can try different values of learning rate, i.e. [1e-2, 1e-3, 1e-4, 5e-3, 5e-4] and others. Check learning process to get the best value.\n",
        "\n",
        "optimizer = AdamW(model.parameters(), \n",
        "                  lr=1e-3)                                          \n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 10,  # You can try different values.\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Kq9YuJpuOFRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7d20f5ee-07f2-425f-d7de-9f49733d5abc"
      },
      "source": [
        "train_history, val_history = fit(model, loss_function, train_loader, val_loader, optimizer, epochs, batch_size, scheduler, type_nn='CNN')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/96 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "Epoch [1 / 8] Train: - accuracy: 0.63, loss: 0.67: 100%|██████████| 96/96 [00:22<00:00,  4.23it/s]\n",
            "Epoch [1 / 8]   Val: - accuracy: 0.74, loss: 0.55: 100%|██████████| 24/24 [00:02<00:00, 11.54it/s]\n",
            "Epoch [2 / 8] Train: - accuracy: 0.73, loss: 0.54: 100%|██████████| 96/96 [00:23<00:00,  4.13it/s]\n",
            "Epoch [2 / 8]   Val: - accuracy: 0.76, loss: 0.52: 100%|██████████| 24/24 [00:02<00:00, 11.70it/s]\n",
            "Epoch [3 / 8] Train: - accuracy: 0.78, loss: 0.47: 100%|██████████| 96/96 [00:22<00:00,  4.26it/s]\n",
            "Epoch [3 / 8]   Val: - accuracy: 0.77, loss: 0.49: 100%|██████████| 24/24 [00:02<00:00, 11.83it/s]\n",
            "Epoch [4 / 8] Train: - accuracy: 0.80, loss: 0.42: 100%|██████████| 96/96 [00:22<00:00,  4.29it/s]\n",
            "Epoch [4 / 8]   Val: - accuracy: 0.78, loss: 0.47: 100%|██████████| 24/24 [00:02<00:00, 11.70it/s]\n",
            "Epoch [5 / 8] Train: - accuracy: 0.83, loss: 0.38: 100%|██████████| 96/96 [00:22<00:00,  4.21it/s]\n",
            "Epoch [5 / 8]   Val: - accuracy: 0.79, loss: 0.48: 100%|██████████| 24/24 [00:02<00:00, 11.64it/s]\n",
            "Epoch [6 / 8] Train: - accuracy: 0.85, loss: 0.34: 100%|██████████| 96/96 [00:22<00:00,  4.22it/s]\n",
            "Epoch [6 / 8]   Val: - accuracy: 0.77, loss: 0.49: 100%|██████████| 24/24 [00:02<00:00, 11.67it/s]\n",
            "Epoch [7 / 8] Train: - accuracy: 0.87, loss: 0.31: 100%|██████████| 96/96 [00:22<00:00,  4.24it/s]\n",
            "Epoch [7 / 8]   Val: - accuracy: 0.78, loss: 0.49: 100%|██████████| 24/24 [00:02<00:00, 11.73it/s]\n",
            "Epoch [8 / 8] Train: - accuracy: 0.89, loss: 0.27: 100%|██████████| 96/96 [00:22<00:00,  4.24it/s]\n",
            "Epoch [8 / 8]   Val: - accuracy: 0.78, loss: 0.52: 100%|██████████| 24/24 [00:02<00:00, 11.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNlB8uwsbn7Z",
        "colab_type": "text"
      },
      "source": [
        "# Resume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6UyJNPbrfg",
        "colab_type": "text"
      },
      "source": [
        "Our best model is BERT with accuracy score = 0.83. But we have a lightweight and fast model with accuracy score = 0.81 it the Logistic regression on TF-IDF char level features. Choosing the best model depends on your task and data that you have to be smart and experiment.\n"
      ]
    }
  ]
}